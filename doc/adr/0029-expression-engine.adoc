= 29 Expression engine

Date: 2021-10-14

== Status

Accepted

== Context

XTDB should be able to compile efficient expressions over Arrow vectors and support low-level SQL-semantics.

We currently have a basic expression engine that can deal with some of this.
The expression engine is currently used by the project and select operators and supports a limited set of scalar types.

* The current expression engine is built around typed multi-methods that return code snippets that are stitched together.
  These are only called once per batch, and the entire resulting expression is cached.
  The result is compiled into a tight loop.
* The group-by operator is currently handled by a bespoke system.

== Decision

* The expression engine should support the full Arrow type system.
+
The feature focus should be on types XTDB itself can ingest, but it needs to handle other types (fixed width binary and lists, unsigned numbers) gracefully.
* The engine should continue to be extensible and able to support the basic expected functions in SQL.
* The group-by operator in the logical plan should use the same semantics as the operators in the expression engine for aggregation.
* The order-by operator in the logical plan should behave the same way as the comparison operators of the expression engine.
+
How to compare different types, lists and structs needs to be defined, potentially taking a hint from PartiQL.
Alternatively, we can be strict like SQL.

Regarding the performance of the expression engine:
* The expression engine needs to compile small, efficient kernels on demand.
* All overhead should move to per-batch where possible.
* Primitive operators and stack allocated locals should be used in the inner loop.
* NULL checks should be elided when possible.

== Other considerations

=== Datalog/SQL

* EDN Datalog has Clojure-like semantics, and behave different to SQL, especially when it comes to dealing with NULLs and use binary boolean logic where NULL is treated as FALSE.
* It also operates on Java types, and not the Arrow type system.

==== Decision

* Datalog and SQL should share the low-level semantics, for reasons of both technical and clarity.
  Where they differ, we should opt for the SQL behaviour as it is defined in the relevant standard.
  (That said, it may be possible to make the expression engine have different modes when it comes to NULL.)

* When numeric of temporal types needs to be widened, or NULLs are involved in expressions, we need to be able to do what the SQL specification expects.
+
A special common case of this is support for three-valued boolean logic.

=== Numeric types

The SQL:2011 standard (§4.4) distinguishes between 'exact' (e.g. integers, longs, BigDecimals) and 'approximate' (e.g. floats, doubles) numeric values.
For exact numbers, it defines 'precision' as the amount of binary/decimal digits available (e.g. 32 bit integers).
(It also defines 'scale', a multiplying factor used to help represent very large/very small numbers in BigDecimals - we can ignore that here)
Approximate values have the standard floating-point exponent and mantissa concepts.

§6.27 defines the behaviour of numeric expressions, particularly with regard to numeric overflow.

The 'precision' of the results of arithmetic operations is generally 'implementation-dependent', which is not particularly helpful to us!
In Postgres, for example, for addition and subtraction, the precision of the result is the maximum of the precision of the input values - i.e. int + int = int, int + long = long.

Importantly, though, if the addition/subtraction overflows under these rules:

[quote, SQL:2011 §6.27 General Rules]
====
[start=5]
. If the most specific type of the result of an arithmetic operation is exact numeric, then
+
Case:
+
.. If the operator is not division and the mathematical result of the operation is not exactly representable with the precision and scale of the result data type, then an exception condition is raised: `data exception — numeric value out of range`.
.. If the operator is division and the approximate mathematical result of the operation represented with the precision and scale of the result data type loses one or more leading significant digits after rounding or truncating if necessary, then an exception condition is raised: `data exception — numeric value out of range`.
  The choice of whether to round or truncate is implementation-defined.
. If the most specific type of the result of an arithmetic operation is approximate numeric and the exponent of the approximate mathematical result of the operation is not within the implementation-defined exponent range for the result data type, then an exception condition is raised: `data exception — numeric value out of range`.
====

In Postgres's case, for example, `2e9::int + 2e9::int` throws an exception.

Notably, this differs from the default Java behaviour, which instead uses integer wrap-around.

==== Decision

* We will follow the guidance from the SQL:2011 standard regarding when to throw numerical exceptions, rather than Java or Clojure's default semantics.
  For example, we may use the `java.lang.Math/*Exact` functions (or equivalent) to do so.
* Where SQL:2011 specifies 'implementation-dependent', we will take inspiration from Postgres's behaviour, as a de-facto standard.

== Consequences
